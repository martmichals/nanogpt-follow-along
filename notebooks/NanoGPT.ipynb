{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1b94b6-88b8-4b7b-b459-e5b880c12fdd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c54de0-7be3-4e01-b8c7-d7ebc319573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e804868b-85cf-4bc6-bffb-4a03bb36ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de13db-8d1a-40db-b6e3-84f2813c2aaf",
   "metadata": {},
   "source": [
    "# Setting Up Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45f10d88-522a-47b9-9fda-5776c2203fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('../data/input.txt', 'r', encoding='utf-8') as inf:\n",
    "    text = inf.read()\n",
    "print(f'Length of dataset in characters: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac49788-a6e1-44d2-a2da-7dc303d83a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "# Set up the vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f'Vocabulary size: {len(chars)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "625216af-761a-4dfc-9b09-2bcc382d1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the encoder and decoder\n",
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[ch] for ch in s] # str -> List[int]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])   # List[int] -> str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b42de-c766-4dc2-a1c4-db136f58509b",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f8c8b2-65e3-4bfc-ab91-0f4e7c0126e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmartmichals\u001b[0m (\u001b[33mmartymcfly\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/martmichals/envs/nanogpt-follow-along/notebooks/wandb/run-20231216_133646-mq2rnkvk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/martymcfly/nanogpt/runs/mq2rnkvk' target=\"_blank\">train-bigram-baseline</a></strong> to <a href='https://wandb.ai/martymcfly/nanogpt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/martymcfly/nanogpt' target=\"_blank\">https://wandb.ai/martymcfly/nanogpt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/martymcfly/nanogpt/runs/mq2rnkvk' target=\"_blank\">https://wandb.ai/martymcfly/nanogpt/runs/mq2rnkvk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(name='train-bigram-baseline', job_type='training')\n",
    "artifact = run.use_artifact('nanogpt/mini-shakespeare-tensors:latest')\n",
    "data_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d423ca8-b52d-4919-a9b2-9f4a071da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train = torch.load(os.path.join(data_dir, 'train.pt'))\n",
    "val   = torch.load(os.path.join(data_dir, 'val.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ddb03fa-9b28-439e-9cf0-bcc5f79f63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Context window size\n",
    "block_size = 8\n",
    "train[:block_size+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234f60a-79ee-44e1-95c6-c7ac19719e44",
   "metadata": {},
   "source": [
    "Below are examples of training samples for the transformer. We arrange the training samples this way s.t. at runtime, the model is used to seeing context sizes of varying lengths, from 1 token of context all the way up until `block_size` tokens of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61307eee-427d-4dac-a2e0-8f778e2946bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target is: 47\n",
      "When input is tensor([18, 47]) the target is: 56\n",
      "When input is tensor([18, 47, 56]) the target is: 57\n",
      "When input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "# Show training samples\n",
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When input is {context} the target is: {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e553911-c465-4eb3-a2c8-94fe4aeff3c4",
   "metadata": {},
   "source": [
    "Here we define a function to sample batches from the training or validation datasets. The returned samples are all `block_size` tokens long, with offset prediction tokens. Refer to this later in the training process, since the above implies the training process needs to somehow learn across varying input sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62cc9f26-6fbc-44ef-9dda-efb962a9dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "Output:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "-------\n",
      "Enumeration of all training samples\n",
      "When input is tensor([24]) the target is: 43\n",
      "When input is tensor([24, 43]) the target is: 58\n",
      "When input is tensor([24, 43, 58]) the target is: 5\n",
      "When input is tensor([24, 43, 58,  5]) the target is: 57\n",
      "When input is tensor([24, 43, 58,  5, 57]) the target is: 1\n",
      "When input is tensor([24, 43, 58,  5, 57,  1]) the target is: 46\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46]) the target is: 43\n",
      "When input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target is: 39\n",
      "When input is tensor([44]) the target is: 53\n",
      "When input is tensor([44, 53]) the target is: 56\n",
      "When input is tensor([44, 53, 56]) the target is: 1\n",
      "When input is tensor([44, 53, 56,  1]) the target is: 58\n",
      "When input is tensor([44, 53, 56,  1, 58]) the target is: 46\n",
      "When input is tensor([44, 53, 56,  1, 58, 46]) the target is: 39\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39]) the target is: 58\n",
      "When input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target is: 1\n",
      "When input is tensor([52]) the target is: 58\n",
      "When input is tensor([52, 58]) the target is: 1\n",
      "When input is tensor([52, 58,  1]) the target is: 58\n",
      "When input is tensor([52, 58,  1, 58]) the target is: 46\n",
      "When input is tensor([52, 58,  1, 58, 46]) the target is: 39\n",
      "When input is tensor([52, 58,  1, 58, 46, 39]) the target is: 58\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58]) the target is: 1\n",
      "When input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target is: 46\n",
      "When input is tensor([25]) the target is: 17\n",
      "When input is tensor([25, 17]) the target is: 27\n",
      "When input is tensor([25, 17, 27]) the target is: 10\n",
      "When input is tensor([25, 17, 27, 10]) the target is: 0\n",
      "When input is tensor([25, 17, 27, 10,  0]) the target is: 21\n",
      "When input is tensor([25, 17, 27, 10,  0, 21]) the target is: 1\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1]) the target is: 54\n",
      "When input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target is: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split: str):\n",
    "    # Generate a batch of inputs x and targets y\n",
    "    data = train if split == 'train' else val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "# Show a batch sample\n",
    "xb, yb = get_batch('train')\n",
    "print('Input:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('Output:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('-------\\nEnumeration of all training samples')\n",
    "\n",
    "# Show all the training samples, xb is 4 x 8, which means we have 32 independent training examples, enumerated below\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'When input is {context} the target is: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4789a2fa-67a2-4747-a351-8cfe745544f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "# Show sample\n",
    "print(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a5015-8f3b-4b7b-b96e-552c6caf1f88",
   "metadata": {},
   "source": [
    "# Mathematical Trick\n",
    "We only want tokens to attend to previous tokens, i.e. $x_t$ can only attend to tokens $x_{\\{1, 2, \\dots, t-1\\}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9c2e1aa1-4b8a-4f7e-a87c-500500401676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2  # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7d67d-038e-448b-8ceb-6df4341257f0",
   "metadata": {},
   "source": [
    "One way to do this is to compute the average representation of the preceeding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e1640b0-e200-4020-b5e2-52122cdd2ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x[b, t] = mean_{i<=t} x[b, i]\n",
    "# This does not consider the ordering of the previous tokens, hence BOW\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec44cd0f-a8ee-4e52-8741-d0c2d92050ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2, using matrix mulitplication\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = tril\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B*, T, T) @ (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow2, atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1174a83a-004b-4d85-9c09-a3ef62cf7b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3, different method of matrix generation\n",
    "# we start at zero here, in the future this matrix will be data-dependent, representing inter-token affinities (i.e. how much to attend to each token)\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3, atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f8b569f-de5d-43d1-8b6c-e787897f3abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4, self attention\n",
    "# we now make the weights for averaging data-dependent\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single-head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)   # matrix mulitply with fixed weights, no bias \n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "# note that all tokens are transformed independently\n",
    "k = key(x)   # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "v = value(x) # (B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ v\n",
    "\n",
    "# hear, out of dim (B, T, head_size), represents, for each time step, a value \"predicted\" using information from the past w/self-attention weightings\n",
    "# this is how we end up with B*T samples for each sequence sampled from the training corpus\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0a483-cf2c-4721-849a-ef1723fe83b8",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "- Attention is a communication mechanism. Can view as nodes in a directed graph looking at each other and aggregating information via weighted sums of representations from nodes pointing to a given node.\n",
    "- There is no notion of space here in the vector representations, hence the positional encodings.\n",
    "- Batches are independent of one another.\n",
    "- This is a decoder block, as we are training to predict a value at each time step, the next proper value whilst only attending to the previous tokens. We can turn this into an encoder block by commenting the `tril` masking line, allowing tokens to attend to tokens before and after the current time step.\n",
    "- \"self-attention\" since k, q, v all come from the same x. Sometimes k, v can come from a separate source of nodes, in which case we call this \"cross-attention\"\n",
    "- scaled attention additionally divides `wei` by $\\frac{1}{\\sqrt{\\text{hsize}}}$. This makes it s.t. when input Q, K are unit variance, `wei` will be unit variance as well and the softmax will stay diffuse and not saturate too much, see below. W/o diffused vectors, softmax will converge to one-hot vectors, which is not desired behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c2c85141-e8d9-4b88-a90b-b3bccfdbfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d485bcf-366f-4f17-8a14-fba89cee9426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0700) tensor(0.9006) tensor(18.0429)\n"
     ]
    }
   ],
   "source": [
    "print(k.var(), q.var(), wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1bc50e4-1aa5-406f-b22e-d60e4682cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = wei * (head_size**-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "66238548-ec73-44b1-88dc-2da15ec33db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0700) tensor(0.9006) tensor(1.1277)\n"
     ]
    }
   ],
   "source": [
    "print(k.var(), q.var(), wei.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38c6bb-a3ba-4805-8eca-323e50e6aef5",
   "metadata": {},
   "source": [
    "Below we highlight how matrix mulitplication may be used in order to calculate an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a97d3bf1-c72a-4099-8e05-2b9a5293a835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print('a')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c')\n",
    "print(c)\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5071e754-6798-492d-ba82-9a96f3f3d74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44d7c8-ec3e-4404-ae85-d72bcef487d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
